{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1:\n",
    "Text to data Conversion:\n",
    "The following code will be using doc2vec as it is more representative of the text with the context, as compared to vectorizer which simply counts the number of times a word is found in the data.\n",
    "Algorithm:\n",
    "The following shall use Stacking to predict the classes for the books."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_training_file = \"project_data_files/book_rating_train.csv\"\n",
    "book_testing_file = \"project_data_files/book_rating_test.csv\"\n",
    "\n",
    "train_names_file = \"project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\"\n",
    "train_authors_file = \"project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\"\n",
    "train_desc_file = \"project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\"\n",
    "\n",
    "test_names_file = \"project_data_files/book_text_features_doc2vec/test_name_doc2vec100.csv\"\n",
    "test_authors_file = \"project_data_files/book_text_features_doc2vec/test_authors_doc2vec20.csv\"\n",
    "test_desc_file = \"project_data_files/book_text_features_doc2vec/test_desc_doc2vec100.csv\"\n",
    "\n",
    "train_data = pd.read_csv(book_training_file)\n",
    "test_data = pd.read_csv(book_testing_file)\n",
    "\n",
    "word_training_files = [train_names_file, train_authors_file, train_desc_file]\n",
    "word_testing_files = [test_names_file, test_authors_file, test_desc_file]\n",
    "\n",
    "word_train_data = [pd.read_csv(filename, index_col = False, delimiter = ',', header=None) for filename in word_training_files]\n",
    "word_test_data = [pd.read_csv(filename, index_col = False, delimiter = ',', header=None) for filename in word_testing_files]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline: 0R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 5.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zero_R(labels):\n",
    "    ratings, rating_counts = np.unique(labels, return_counts=True)\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    max_prob = (0, labels[0])\n",
    "    for i in range(len(ratings)):\n",
    "        prob = rating_counts[i] / num_labels\n",
    "        if prob > max_prob[0]:\n",
    "            max_prob = (prob, ratings[i])\n",
    "    return max_prob[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18450, 9), (18450,), (4613, 9), (4613,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data[train_data.columns[:-1]], train_data[train_data.columns[-1]], test_size=0.2, random_state=1169800)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
